#!/usr/bin/env python3



from bottle import route, run, template,redirect,request
from datetime import datetime,timedelta,date
import pandas as pd
import os
import numpy as np
import json
stat_path='/opt/GITHUB_REPOSITORY/log/stats/'

@route('/')
def index(out_type='html'):
    if json=='json':
        return os.listdir(stat_path)

    out=""
    for folder in os.listdir(stat_path):
        out+=f"<a href='daily/{folder}/'>{folder}</a> <br/>"
    return out
@route('/json')
def index_json():
    return index(out_type='json')


@route('/daily/<folder>/json')
def daily_json(folder):
    return daily(folder,out_type='json')


@route('/daily/<folder>/')
def daily(folder,out_type='html'):
    root=f'{stat_path}/{folder}'
    dates=sorted(os.listdir(root))
    
    date_dic={day: [h.split('.')[0] for h in sorted(os.listdir(f'{root}/{day}')) ] for day in dates}
    
    if out_type=='json':
        return date_dic

    out="<a href='json'>json</a><table><tr><th>date</th><th>hour</th></tr>"
    out+=f"<tr><td><a href='0/'>today</a></td><td><a href='1/'>yesterday</a> <a href='0:6/'>last 7 days</a> <a href='0:30/'>last 30 days</a></td></tr>"
    for day,hours in date_dic.items():
        hh=' '.join([f"<a href='{day}-{h}/'>{h}</a>" for h in hours])
        out+=f"<tr><td><a href='{day}/'>{day}</a></td><td>{hh}</td></tr>"
    
    out+='</table>'
    
    
    return out


# def hourly_redirect(folder,date):
#     return redirect(f"{date}/")
@route('/daily/<folder>/<date>/json')
@route('/daily/<folder>/<date>/<per>/json')
def hourly_json(folder,date,per=''):
    return daily_range(folder,date,out_type='json',per=per)


def rel_date(date_in):
    rel=None
    if type(date_in)==int:
        rel=abs(date_in)
    elif date_in.isnumeric():
        rel=abs(int(date_in))
    
    
    if rel is not None and rel<1000:
        return (date.today()-timedelta(days=rel)).strftime("%Y%m%d")
    
    return date_in

@route('/daily/<folder>/<dates>/')
@route('/daily/<folder>/<dates>/<per>/')
def daily_range(folder,dates='',out_type="html",per=''):

    dates=dates.split(',') if len(dates) else []
    final_dates=[]
    for date in dates:
        if ':' in date:
            splt=date.split(':')
            for i in range(int(splt[0]),int(splt[1])):
                final_dates.append(rel_date(i))
        else:
            final_dates.append(rel_date(date))

    if out_type=='html':
        total=None
        for date in final_dates:
            daydf=daily_aggregate(folder,date,per=per)    
            if total is None:
                total=daydf
            elif daydf is not None:
                total=total.add(daydf,fill_value=0)
        
        return f'<a href="json">json</a><br/>' + format_table(total)

    res={}
    for date in final_dates:
        res[date]=hourly(folder,date,out_type=out_type,per=per)
    
    return res
    
    
def daily_aggregate(folder,date,per=''):
    root=f'{stat_path}/{folder}'
    per=per.split(',') if len(per) else []
    hours=[f'{i:02}' for i in range(24)]
    if '-' in date:
        dateobj=datetime.strptime(date,"%Y%m%d-%H")
        date=dateobj.strftime("%Y%m%d")
        hours=[dateobj.strftime("%H")]
    
    alldf=''
    total=None
    root=f'{root}/{date}'

    hours_files=sorted(os.listdir(root)) if os.path.isdir(root) else []
    for hour in sorted(hours_files):
        # if date not in hour:continue
        hour_name=hour.split('.')[0]
        if hour_name not in hours:continue
        if not os.path.isfile(f'{root}/{hour}'):continue
        
        df=pd.read_csv(f'{root}/{hour}',dtype={'haship':'Int64','download':'Int64','upload':'Int64','connection_count':'Int64','unique_ips':'Int64'})
        df=df.set_index([col for col in df.columns if col in ['status','upstream','haship','asn_name','country_code','province','city']])
        if total is None:
            total=df
        else:
            total=total.add(df,fill_value=0)

    if total is not None:
        if 'haship' in total.index.names:
            total,unique_users=aggregate_users(total)
            
        if len(per):
            total=total.groupby(per).sum()

    return total


def hourly(folder,date,out_type="html",per=''):
    root=f'{stat_path}/{folder}'
    per=per.split(',') if len(per) else []
    out_json={}
    out_html=""
    hours=[f'{i:02}' for i in range(24)]
    if '-' in date:
        dateobj=datetime.strptime(date,"%Y%m%d-%H")
        date=dateobj.strftime("%Y%m%d")
        hours=[dateobj.strftime("%H")]
    
    alldf=''
    total=None
    root=f'{root}/{date}'
    if len(hours)!=1:
       out_json['hours']={} 
    hours_files=sorted(os.listdir(root)) if os.path.isdir(root) else []
    for hour in sorted(hours_files):
        # if date not in hour:continue
        hour_name=hour.split('.')[0]
        if hour_name not in hours:continue
        if not os.path.isfile(f'{root}/{hour}'):continue
        
        df=pd.read_csv(f'{root}/{hour}',dtype={'haship':'Int64','download':'Int64','upload':'Int64','connection_count':'Int64','unique_ips':'Int64'})
        df=df.set_index([col for col in df.columns if col in ['status','upstream','haship','asn_name','country_code','province','city']])
        if total is None:
            total=df
        else:
            total=total.add(df,fill_value=0)
        
        if len(hours)!=1:
            out_json['hours'][hour_name]={}
            out_html+=f'<h5>time: {date} {hour_name}:00:00 to {hour_name}:59:59</h5><a href="../{date}-{hour_name}/json">json</a><br/>'
            if 'haship' in df.index.names:
                df,unique_users=aggregate_users(df)
                out_html+=f"<h8>{unique_users} unique ips</h8>"
                out_json['hours'][hour_name]['unique_ips']=unique_users
            if len(per):
                df=df.groupby(per).sum()
            out_json['hours'][hour_name]['details']=df_to_dict(df)
            out_html+=format_table(df)

    if total is not None:
        out_json['total']={}
        out_html_total=f'<a href="json">json</a><br/>'
        if 'haship' in total.index.names:
            total,unique_users=aggregate_users(total)
            out_html_total+=f"<h8>{unique_users} unique ips</h8>"
            out_json['total']['unique_ips']=unique_users
            
        if len(per):
            total=total.groupby(per).sum()
        out_html_total+=format_table(total)
        out_json['total']['details']=df_to_dict(total)

        if len(hours)!=1:
            out_html=f'<h1>Total {date}</h1>{out_html_total}<h1>Hourly</h1>{out_html}' 
        else:
            out_html=f'<h1>Hour {date} {hour_name}:00:00 to {hour_name}:59:59</h1>{out_html_total}'

    if out_type=='json':
        return out_json
    return out_html

def format_table(df):
    if df is None:
        return ""
    df=df.copy()
    df['download']=(df['download']/1024/1024/1024).round(3)
    df['upload']=(df['upload']/1024/1024/1024).round(3)
    df=df.rename({'upload':'upload (GB)', 'download':'download (GB)'},axis=1)

    return df.to_html()

@route('/daily/<folder>')
@route('/daily/<folder>/<date>')
@route('/daily/<folder>/<date>/<per>')
def error(folder='',date='',per=''):
    newu=request.url.split('/')[-1]
    return f"this page is moved to <a href='{newu}/'>{newu}/</a>"


    
def aggregate_users(df):
    indx=list(df.index.names)
    indx.remove('haship')
    cols_agg={c:'sum' for c in df.columns}
    cols_agg['haship']='nunique'

    df=df.reset_index()
    unique_users=len(df['haship'].unique())
    df=df.groupby(indx).agg(cols_agg).rename(columns={'haship':'unique_ips'})
    return df,unique_users


def df_to_dict(df):
    data=df.stack().to_dict()
    d = {}
    for t, v in data.items():
     e = d.setdefault(t[0], {})
     for k in t[1:-1]:
        e = e.setdefault(k, {})
     e[t[-1]] = v
    return d

run(host='localhost', port=440)
